{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LWEH6x_cSliu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Function to perform Effort to Compress (ETC)\n",
        "def etc(arr):\n",
        "    # Check if the array is empty\n",
        "    if len(arr) == 0:\n",
        "        print(\"Error: Empty array provided.\")\n",
        "        return 0\n",
        "\n",
        "    iteration = 0  # Initialize the iteration count\n",
        "    while True:\n",
        "        iteration += 1  # Increment the iteration count\n",
        "        hash = [0] * 256  # Initialize a hash array to count occurrences of characters\n",
        "        n = len(arr)  # Get the length of the array\n",
        "        mp = {}  # Initialize a dictionary to store pairs of adjacent elements\n",
        "        # Iterate through the array to count character occurrences and pairs of adjacent elements\n",
        "        for i in range(n-1):\n",
        "            a = arr[i]\n",
        "            hash[a] += 1\n",
        "            b = arr[i+1]\n",
        "            if (a, b) in mp:\n",
        "                mp[(a, b)] += 1\n",
        "            else:\n",
        "                mp[(a, b)] = 1\n",
        "        hash[arr[n-1]] += 1  # Count the occurrence of the last element\n",
        "        finish = False  # Flag to indicate if all characters are the same\n",
        "        # Check if all characters are the same\n",
        "        for i in range(256):\n",
        "            if hash[i] == n:\n",
        "                finish = True\n",
        "                break\n",
        "        if finish:\n",
        "            # Algorithm ends as all characters are the same\n",
        "            break\n",
        "\n",
        "        mx = (0, 0)  # Initialize a pair to store the most frequent adjacent elements\n",
        "        mxcnt = 0  # Initialize a counter for the most frequent pair\n",
        "        # Find the most frequent pair of adjacent elements\n",
        "        for key, value in mp.items():\n",
        "            if value > mxcnt:\n",
        "                mx = key\n",
        "                mxcnt = value\n",
        "        replace = -1  # Initialize a variable to store the character to be replaced\n",
        "        # Find a character that is not used in the array\n",
        "        for i in range(256):\n",
        "            if hash[i] == 0:\n",
        "                replace = i\n",
        "                break\n",
        "        if replace == -1:\n",
        "            print(\"Error: all characters are used\")\n",
        "            return iteration\n",
        "\n",
        "        newarr = []  # Initialize a new array to store the transformed elements\n",
        "        i = 0  # Initialize an index variable\n",
        "        while i < n-1:\n",
        "            a = arr[i]\n",
        "            b = arr[i+1]\n",
        "            if a == mx[0] and b == mx[1]:\n",
        "                # Replace the most frequent pair with the character that is not used\n",
        "                newarr.append(replace)\n",
        "                i += 1\n",
        "            else:\n",
        "                newarr.append(a)\n",
        "            i += 1\n",
        "        if i == n - 1:\n",
        "            newarr.append(arr[i])\n",
        "        # Append the last element if it's not part of the most frequent pair\n",
        "        if arr[n-1] == mx[1] and arr[n-2] == mx[0]:\n",
        "            pass\n",
        "        else:\n",
        "            newarr.append(arr[n-1])\n",
        "        arr = np.array(newarr)  # Convert the new array to numpy array for further processing\n",
        "    return iteration - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dvvsNKofUlNO"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        ''' constructor '''\n",
        "\n",
        "        # for decision node\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "\n",
        "        # for leaf node\n",
        "        self.value = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9DoBbEzsUnVa"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeClassifier():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        ''' constructor '''\n",
        "\n",
        "        # initialize the root of the tree\n",
        "        self.root = None\n",
        "\n",
        "        # stopping conditions\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        ''' recursive function to build the tree '''\n",
        "\n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "\n",
        "        # split until stopping conditions are met\n",
        "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
        "            # find the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            # check if information gain is positive\n",
        "            if best_split[\"info_gain\"]>0:\n",
        "                # recur left\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
        "                # recur right\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
        "                # return decision node\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "\n",
        "        # compute leaf node\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        # return leaf node\n",
        "        return Node(value=leaf_value)\n",
        "\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        ''' function to find the best split '''\n",
        "\n",
        "        # dictionary to store the best split\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "\n",
        "        # loop over all the features\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            # loop over all the feature values present in the data\n",
        "            for threshold in possible_thresholds:\n",
        "                # get current split\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # check if childs are not null\n",
        "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    # compute information gain\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"etc\")\n",
        "                    # update the best split if needed\n",
        "                    if curr_info_gain>max_info_gain:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"info_gain\"] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "\n",
        "        # return best split\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        ''' function to split the data '''\n",
        "\n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "        return dataset_left, dataset_right\n",
        "\n",
        "    def etc(self, y):\n",
        "        y = list(y.astype(int))\n",
        "\n",
        "        \"Computes ETC of the given sequence\"\n",
        "        if len(y) == 1:\n",
        "            return 0\n",
        "        else:\n",
        "            out =  etc(y)\n",
        "            return out\n",
        "    ############## START OF ETC CODE ###########\n",
        "    def etc_gain(self, parent, l_child, r_child):\n",
        "        left = l_child\n",
        "        right = r_child\n",
        "        \"\"\"\n",
        "        Computes the etc gain from splitting the parent dataset into two datasets.\n",
        "\n",
        "        Parameters:\n",
        "            parent (ndarray): Input parent dataset.\n",
        "            left (ndarray): Subset of the parent dataset after split on a feature.\n",
        "            right (ndarray): Subset of the parent dataset after split on a feature.\n",
        "\n",
        "        Returns:\n",
        "            etc_gain_ (float): effor to compress (etc) gain of the split.\n",
        "        \"\"\"\n",
        "\n",
        "        # set initial information gain to 0\n",
        "        etc_gain_ = 0\n",
        "        # compute etc for parent\n",
        "        parent_etc = self.etc(parent)\n",
        "        # calculate weight for left and right nodes\n",
        "        weight_left = len(left) / len(parent)\n",
        "        weight_right= len(right) / len(parent)\n",
        "        # compute etc for left and right nodes\n",
        "\n",
        "        etc_left, etc_right = self.etc(left), self.etc(right)\n",
        "        # calculate weighted entropy\n",
        "        weighted_etc = weight_left * etc_left + weight_right * etc_right\n",
        "        # calculate etc gain\n",
        "        etc_gain_ = parent_etc - weighted_etc\n",
        "        #print(\"ETC Gain = \", etc_gain_)\n",
        "        return etc_gain_\n",
        "###########################\n",
        "\n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"etc\"):\n",
        "        ''' function to compute information gain '''\n",
        "\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        if mode==\"etc\":\n",
        "            gain = self.etc_gain(parent, l_child, r_child)\n",
        "\n",
        "        return gain\n",
        "\n",
        "    def calculate_leaf_value(self, Y):\n",
        "        ''' function to compute leaf node '''\n",
        "\n",
        "        Y = list(Y)\n",
        "        return max(Y, key=Y.count)\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "        ''' function to print the tree '''\n",
        "\n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "\n",
        "        else:\n",
        "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + indent)\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + indent)\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        Y = np.array(Y).reshape(-1, 1)\n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, X):\n",
        "        ''' function to predict new dataset '''\n",
        "\n",
        "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
        "        return preditions\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "        ''' function to predict a single data point '''\n",
        "\n",
        "        if tree.value!=None: return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tRKdSdMOUsCM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nyse_stock_data.data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/d1/rq8yrnpj2yn8wv9c10c7yll80000gn/T/ipykernel_12888/3974720329.py:125: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  max_f1_score_per_group = results_df.groupby('Shuffle Seed')['Mean F1 Score'].transform(max)\n",
            "/var/folders/d1/rq8yrnpj2yn8wv9c10c7yll80000gn/T/ipykernel_12888/3974720329.py:131: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  min_depth_for_max_f1 = max_f1_rows.groupby('Shuffle Seed').apply(lambda x: x.loc[x['Depth of Tree'].idxmin()])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics PDT:\n",
            "Accuracy: 0.971830985915493\n",
            "F1 Score: 0.9678442028985508\n",
            "Precision: 0.9678442028985508\n",
            "Recall: 0.9678442028985508\n",
            "best_Shuffleseed_used_for_pdt: 1.0\n",
            "Corresponding Depth: 2.0\n",
            "Evaluation Metrics PDF:\n",
            "Accuracy_test_pdf: 0.971830985915493\n",
            "Precision_test_pdf: 0.96\n",
            "F1 Score_test_pdf: 0.9685283687943262\n",
            "Recall_test_pdf: 0.9791666666666667\n",
            "timeseries.py\n",
            "Dataset not found.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Expected sequence or array-like, got <class 'NoneType'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 56\u001b[0m\n\u001b[1;32m     41\u001b[0m time_series_split_test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# _______________________________________________________________________________\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Variable description:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#     y_test          -   Corresponding labels for X_test.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets with the fixed seed\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# print(\"hi boss\", flush=True)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Perform experiments for each seed value for shuffling training data\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shuffle_seed \u001b[38;5;129;01min\u001b[39;00m shuffle_seed_values:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Shuffle only the training data with the current seed\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pdt/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pdt/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2659\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m-> 2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2662\u001b[0m )\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pdt/lib/python3.10/site-packages/sklearn/utils/validation.py:378\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    376\u001b[0m         x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'NoneType'>"
          ]
        }
      ],
      "source": [
        "# importing dataset\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "import numpy as np\n",
        "from load import load\n",
        "import time\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "# Define the path to the datasets folder\n",
        "datasets_folder = os.path.join(current_directory, \"datasets\")\n",
        "# List all the datasets in the folder, excluding hidden files\n",
        "exclude_datasets = ['ionosphere', 'breastcancerwisconsin', 'wine', 'appendicitis', 'diabetespimaindian', 'sonar', 'iris', 'rice', 'timeseries.py']\n",
        "\n",
        "datasets = [dataset for dataset in os.listdir(datasets_folder) if not (dataset.startswith('.') or dataset in exclude_datasets)]\n",
        "# st = time.time()\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "    # importing dataset\n",
        "    print(dataset_name)\n",
        "    X, Y = load(dataset_name)\n",
        "\n",
        "    # Define the number of splits for time series split\n",
        "    num_splits = 5\n",
        "\n",
        "    # Fix the seed value for splitting data\n",
        "    split_seed = 42\n",
        "\n",
        "    # Define different seed values for shuffling training data\n",
        "    shuffle_seed_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "\n",
        "    # Define the range of depths for the decision tree\n",
        "    depth_range = range(2, 21)\n",
        "\n",
        "    # Initialize a list to store the results\n",
        "    results = []\n",
        "    # declaring test size for time series split\n",
        "    time_series_split_test_size = 15\n",
        "\n",
        "    # _______________________________________________________________________________\n",
        "\n",
        "    # Variable description:\n",
        "    # _______________________________________________________________________________\n",
        "\n",
        "    #     X               -   Data attributes.\n",
        "    #     y               -   Corresponding labels for X.\n",
        "    #     X_train         -   Data attributes for training (80% of the dataset).\n",
        "    #     y_train         -   Corresponding labels for X_train.\n",
        "    #     X_test          -   Data attributes for testing (20% of the dataset).\n",
        "    #     y_test          -   Corresponding labels for X_test.\n",
        "    # Split the data into training and testing sets with the fixed seed\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "    # print(\"hi boss\", flush=True)\n",
        "\n",
        "    # Perform experiments for each seed value for shuffling training data\n",
        "    for shuffle_seed in shuffle_seed_values:\n",
        "        # Shuffle only the training data with the current seed\n",
        "        X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=shuffle_seed)\n",
        "        # print(\"hello\", flush=True)\n",
        "\n",
        "        # Perform time series split\n",
        "        tscv = TimeSeriesSplit(n_splits=num_splits,test_size=time_series_split_test_size)\n",
        "\n",
        "        # Iterate over different depths for the decision tree\n",
        "        for depth in depth_range:\n",
        "            # Initialize lists to store evaluation metrics for each fold\n",
        "            accuracies = []\n",
        "            f1_scores = []\n",
        "            precisions = []\n",
        "            recalls = []\n",
        "\n",
        "            # Perform time series split\n",
        "            for split_num, (train_index, test_index) in enumerate(tscv.split(X_train_shuffled), 1):\n",
        "                X_cv_train, X_cv_test = pd.DataFrame(X_train_shuffled).iloc[train_index].to_numpy(),pd.DataFrame(X_train_shuffled).iloc[test_index].to_numpy()\n",
        "                y_cv_train, y_cv_test = pd.DataFrame(y_train_shuffled).iloc[train_index].to_numpy(), pd.DataFrame(y_train_shuffled).iloc[test_index].to_numpy()\n",
        "                # print(\"check\", flush=True)\n",
        "                # curr_time = time.time()\n",
        "                # print(\"Current time is: \", curr_time - st)\n",
        "\n",
        "                # Train the decision tree model with the current depth\n",
        "                tree_classifier = DecisionTreeClassifier(max_depth=depth)\n",
        "                tree_classifier.fit(X_cv_train, y_cv_train)\n",
        "\n",
        "                # Make predictions\n",
        "                y_pred = tree_classifier.predict(X_cv_test)\n",
        "\n",
        "                # Calculate evaluation metrics for this fold\n",
        "                accuracy = accuracy_score(y_cv_test, y_pred)\n",
        "                f1 = f1_score(y_cv_test, y_pred, average='macro')  # Use macro F1 score\n",
        "                precision = precision_score(y_cv_test, y_pred, average='macro', zero_division = 1)\n",
        "                recall = recall_score(y_cv_test, y_pred, average='macro', zero_division = 1)\n",
        "\n",
        "                # Append metrics to the lists\n",
        "                accuracies.append(accuracy)\n",
        "                f1_scores.append(f1)\n",
        "                precisions.append(precision)\n",
        "                recalls.append(recall)\n",
        "\n",
        "            # Calculate mean metrics across all folds\n",
        "            mean_accuracy = sum(accuracies) / len(accuracies)\n",
        "            mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "            mean_precision = sum(precisions) / len(precisions)\n",
        "            mean_recall = sum(recalls) / len(recalls)\n",
        "\n",
        "            # Store the results for this seed value and depth\n",
        "            results.append({\n",
        "                'Split Seed': split_seed,\n",
        "                'Shuffle Seed': shuffle_seed,\n",
        "                'Depth of Tree': depth,\n",
        "                'Mean Accuracy': mean_accuracy,\n",
        "                'Mean F1 Score': mean_f1,\n",
        "                'Mean Precision': mean_precision,\n",
        "                'Mean Recall': mean_recall\n",
        "            })\n",
        "\n",
        "    # print(\"reached here\")\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    # Group by 'Shuffle Seed' and find the maximum F1 score within each group\n",
        "    max_f1_score_per_group = results_df.groupby('Shuffle Seed')['Mean F1 Score'].transform(max)\n",
        "\n",
        "    # Filter the DataFrame to keep rows where 'Mean F1 Score' is equal to the maximum F1 score within each group\n",
        "    max_f1_rows = results_df[results_df['Mean F1 Score'] == max_f1_score_per_group]\n",
        "\n",
        "    # Group the max_f1_rows DataFrame by 'Shuffle Seed' and find the row with the minimum 'Depth of Tree' within each group\n",
        "    min_depth_for_max_f1 = max_f1_rows.groupby('Shuffle Seed').apply(lambda x: x.loc[x['Depth of Tree'].idxmin()])\n",
        "\n",
        "    # Extracting desired columns\n",
        "    selected_columns = min_depth_for_max_f1[['Split Seed', 'Shuffle Seed', 'Depth of Tree']]\n",
        "\n",
        "    # # Printing the extracted values\n",
        "    # print(\"Shuffle seed values with corresponding depth for maximum F1 score:\")\n",
        "    # for _, row in selected_columns.iterrows():\n",
        "    #     print(f\"{{'Split Seed': {row['Split Seed']}, 'Shuffle Seed': {row['Shuffle Seed']}, 'Depth': {row['Depth of Tree']}}}\")\n",
        "\n",
        "    # Convert the selected columns to a numpy array and save it\n",
        "    parameters_array = selected_columns.to_numpy()\n",
        "\n",
        "    # Convert each row of the numpy array to a dictionary\n",
        "    parameters_list = [{'Split Seed': row[0], 'Shuffle Seed': row[1], 'Depth': row[2]} for row in parameters_array]\n",
        "\n",
        "        # Initialize a list to store the evaluation metrics for each model\n",
        "    evaluation_metrics = []\n",
        "\n",
        "    # Iterate over the top parameters\n",
        "    for i, params in enumerate(parameters_list, start=1):\n",
        "        split_seed = int(params['Split Seed'])  # Convert to integer\n",
        "        shuffle_seed = int(params['Shuffle Seed'])\n",
        "        max_depth = int(params['Depth'])\n",
        "\n",
        "        # Split the dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "        # Shuffle only the training data with the fixed seed\n",
        "        X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=shuffle_seed)\n",
        "\n",
        "        # print(\"arham\")\n",
        "        # Train the decision tree model with the entire training data\n",
        "        tree_classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
        "        tree_classifier.fit(X_train_shuffled, y_train_shuffled)\n",
        "        # print(\"jain\")\n",
        "        #  # Printing the decision tree\n",
        "        # print(f\"Model {i} Decision Tree:\")\n",
        "        # tree_classifier.print_tree()\n",
        "        # print()  # empty line for readability\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred_train_data = tree_classifier.predict(X_train_shuffled.values)\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        accuracy_train = accuracy_score(y_train_shuffled, y_pred_train_data)\n",
        "        f1_train = f1_score(y_train_shuffled, y_pred_train_data, average='macro')\n",
        "        precision_train = precision_score(y_train_shuffled, y_pred_train_data, average='macro',zero_division=1)\n",
        "        recall_train = recall_score(y_train_shuffled, y_pred_train_data, average='macro', zero_division=1)\n",
        "\n",
        "        # Append the evaluation metrics to the list\n",
        "        evaluation_metrics.append({\n",
        "            'Model': i,\n",
        "            'Split Seed': split_seed,\n",
        "            'Shuffle Seed': shuffle_seed,\n",
        "            'Max Depth': max_depth,\n",
        "            'Accuracy_train': accuracy_train,\n",
        "            'F1 Score_train': f1_train,\n",
        "            'Precision_train': precision_train,\n",
        "            'Recall_Train' : recall_train\n",
        "        })\n",
        "\n",
        "            # Find the row with the maximum F1 score\n",
        "    max_f1_row = results_df.loc[results_df['Mean F1 Score'].idxmax()]\n",
        "\n",
        "    # Extract the shuffle seed value with maximum F1 score\n",
        "    shuffle_seed_with_max_f1_score = max_f1_row['Shuffle Seed']\n",
        "\n",
        "    # Find the index of the row with shuffle_seed_with_max_f1_score in parameters list\n",
        "    max_f1_index = None\n",
        "    for idx, params in enumerate(parameters_list):\n",
        "        if params['Shuffle Seed'] == shuffle_seed_with_max_f1_score:\n",
        "            max_f1_index = idx\n",
        "            break\n",
        "\n",
        "    if max_f1_index is not None:\n",
        "        max_f1_params = parameters_list[max_f1_index]\n",
        "\n",
        "    # Finding the depth corresponding to the shuffle seed value\n",
        "    corresponding_depth = max_f1_params['Depth']\n",
        "\n",
        "    # # Print the chosen shuffle seed value\n",
        "    # print(\"Chosen Shuffle Seed for Training:\", shuffle_seed_with_max_f1_score)\n",
        "    # print(\"Corresponding depth:\", corresponding_depth)\n",
        "\n",
        "    # Split the data into training and testing sets using the chosen shuffle seed value\n",
        "    X_train_pdt, X_test_pdt, y_train_pdt, y_test_pdt = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "    # Shuffle only the training data with the chosen shuffle seed value\n",
        "    X_train_shuffled_pdt, y_train_shuffled_pdt = shuffle(X_train_pdt, y_train_pdt, random_state=int(shuffle_seed_with_max_f1_score))\n",
        "\n",
        "    # Train a decision tree classifier with the chosen depth\n",
        "    classifier_pdt = DecisionTreeClassifier(max_depth=corresponding_depth)\n",
        "    classifier_pdt.fit(X_train_shuffled_pdt, y_train_shuffled_pdt)\n",
        "\n",
        "    # Predict labels for the testing data\n",
        "    y_pred_pdt = tree_classifier.predict(X_test_pdt.values)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy_pdt = accuracy_score(y_test_pdt, y_pred_pdt)\n",
        "    f1_score_pdt = f1_score(y_test_pdt, y_pred_pdt, average='macro')\n",
        "    precision_pdt = precision_score(y_test_pdt, y_pred_pdt, average='macro', zero_division=1)\n",
        "    recall_pdt = recall_score(y_test_pdt, y_pred_pdt, average='macro', zero_division=1)\n",
        "\n",
        "    # Print the evaluation metrics\n",
        "    print(\"Evaluation Metrics PDT:\")\n",
        "    print(f\"Accuracy: {accuracy_pdt}\")\n",
        "    print(f\"F1 Score: {f1_score_pdt}\")\n",
        "    print(f\"Precision: {precision_pdt}\")\n",
        "    print(f\"Recall: {recall_pdt}\")\n",
        "    print(f\"best_Shuffleseed_used_for_pdt: {shuffle_seed_with_max_f1_score}\")\n",
        "    print(f\"Corresponding Depth: {corresponding_depth}\")\n",
        "\n",
        "    # Creating this because we want to save the result in form of csv and numpy\n",
        "    evaluation_metrics_pdt = {\n",
        "        \"Accuracy_PDT\": accuracy_pdt,\n",
        "        \"F1 Score_PDT\": f1_score_pdt,\n",
        "        \"Precision_PDT\": precision_pdt,\n",
        "        \"Recall_PDT\": recall_pdt,\n",
        "        \"best_Shuffleseed_used_for_pdt\": shuffle_seed_with_max_f1_score,\n",
        "        \"Corresponding Depth\" : corresponding_depth\n",
        "    }\n",
        "\n",
        "\n",
        "    # Initialize a list to store the top shuffle seeds along with their corresponding depths\n",
        "    top_shuffle_seeds = []\n",
        "\n",
        "    # Iterate over the top parameters\n",
        "    for params in parameters_list:\n",
        "        split_seed = int(params['Split Seed'])\n",
        "        shuffle_seed = int(params['Shuffle Seed'])\n",
        "        depth = int(params['Depth'])\n",
        "        top_shuffle_seeds.append({'Split Seed':split_seed, 'Shuffle Seed': shuffle_seed, 'Depth': depth})\n",
        "\n",
        "    # Load the dataset\n",
        "    X_train_pdf, X_test_pdf, y_train_pdf, y_test_pdf = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "    # Create an empty matrix to store predictions\n",
        "    predictions_matrix = np.zeros((len(X_test), len(top_shuffle_seeds)), dtype=int)\n",
        "\n",
        "    # Iterate over each test sample\n",
        "    # for i, x_test_sample in enumerate(X_test):\n",
        "        # Make predictions using each model\n",
        "    for j, params in enumerate(top_shuffle_seeds):\n",
        "        split_seed = (params['Split Seed'])\n",
        "        shuffle_seed = params['Shuffle Seed']\n",
        "        max_depth = params['Depth']\n",
        "        \n",
        "        # Shuffle only the training data with the fixed seed\n",
        "        X_train_shuffled_pdf, y_train_shuffled_pdf = shuffle(X_train_pdf, y_train_pdf, random_state=shuffle_seed)\n",
        "\n",
        "        # Train the decision tree model with the entire training data\n",
        "        tree_classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
        "        # print(\"reached checkpoint1\")\n",
        "        tree_classifier.fit(X_train_shuffled_pdf, y_train_shuffled_pdf)\n",
        "        # print(\"reached checkpoint2\")\n",
        "        # Make prediction for the current test sample using the trained model\n",
        "        prediction = tree_classifier.predict(X_test_pdf.values)\n",
        "\n",
        "        # Store the prediction in the matrix\n",
        "        predictions_matrix[:, j] = prediction\n",
        "\n",
        "    # Initialize lists to store final predictions and evaluation metrics\n",
        "    final_predictions = []\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    f1_scores = []\n",
        "\n",
        "    # Iterate over each row in the predictions matrix\n",
        "    for i in range(predictions_matrix.shape[0]):\n",
        "        # Find the majority occurring element in the row\n",
        "        majority_prediction = np.bincount(predictions_matrix[i,:]).argmax()\n",
        "\n",
        "        # Append the majority prediction to the final predictions list\n",
        "        final_predictions.append(majority_prediction)\n",
        "    final_prediction = predictions_matrix[:,-1]\n",
        "    # Calculate accuracy, precision, F1-score and recall using the majority prediction and actual test label\n",
        "    accuracy_test_pdf = accuracy_score(y_test_pdf, final_predictions)\n",
        "    precision_test_pdf = precision_score(y_test_pdf, final_predictions, average='macro', zero_division=1)\n",
        "    f1_test_pdf = f1_score(y_test_pdf, final_predictions, average='macro')\n",
        "    recall_test_pdf = recall_score(y_test_pdf, final_predictions, average='macro', zero_division=1)\n",
        "\n",
        "\n",
        "\n",
        "    # Print the final evaluation metrics\n",
        "    print(\"Evaluation Metrics PDF:\")\n",
        "    print(f\"Accuracy_test_pdf: {accuracy_test_pdf}\")\n",
        "    print(f\"Precision_test_pdf: {precision_test_pdf}\")\n",
        "    print(f\"F1 Score_test_pdf: {f1_test_pdf}\")\n",
        "    print(f\"Recall_test_pdf: {recall_test_pdf}\")\n",
        "\n",
        "    # Creating this because we want to save the result in form of csv and numpy\n",
        "    evaluation_metrics_pdf = {\n",
        "        \"Accuracy\": accuracy_test_pdf,\n",
        "        \"F1 Score\": f1_test_pdf,\n",
        "        \"Precision\": precision_test_pdf,\n",
        "        \"Recall\": recall_test_pdf\n",
        "    }\n",
        "\n",
        "    # Define the path to the results folder\n",
        "    results_folder = os.path.join(current_directory, \"results\")\n",
        "\n",
        "    # Define the dataset name\n",
        "    dataset_name = dataset_name\n",
        "\n",
        "    # Create a folder for the current dataset within the results directory\n",
        "    dataset_results_folder = os.path.join(results_folder, dataset_name)\n",
        "    os.makedirs(dataset_results_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "    # Create folders for PDT and pdf within the dataset results folder\n",
        "    pdt_folder = os.path.join(dataset_results_folder, \"PDT\")\n",
        "    pdf_folder = os.path.join(dataset_results_folder, \"PDF\")\n",
        "    os.makedirs(pdt_folder, exist_ok=True)\n",
        "    os.makedirs(pdf_folder, exist_ok=True)\n",
        "\n",
        "    # Path for PDT csv file\n",
        "    pdt_metrics_csv_path = os.path.join(pdt_folder, \"evaluation_metrics_pdt_test.csv\")\n",
        "    # saving this to PDT folder\n",
        "    pd.DataFrame(evaluation_metrics_pdt.items(), columns=[\"Metric\", \"Value\"]).to_csv(pdt_metrics_csv_path, index=False)\n",
        "\n",
        "    # Path for PDT numpy file\n",
        "    pdt_metrics_npy_path = os.path.join(pdt_folder, \"evaluation_metrics_pdt_test.npy\")\n",
        "    #saving it to PDT folder\n",
        "    np.save(pdt_metrics_npy_path, evaluation_metrics_pdt)\n",
        "\n",
        "    # Convert evaluation_metrics to DataFrame\n",
        "    training_data_df = pd.DataFrame(evaluation_metrics)\n",
        "    # Path for Training metrics csv file\n",
        "    training_metrics_csv_path = os.path.join(pdt_folder, \"evaluation_metrics_training_data_of_top_paramaters.csv\")\n",
        "    # saving this to PDT folder\n",
        "    training_data_df.to_csv(training_metrics_csv_path, index=False)\n",
        "\n",
        "    # Path for Training metrics numpy file\n",
        "    training_metrics_npy_path = os.path.join(pdt_folder, \"evaluation_metrics_training_data_of_top_paramaters.npy\")\n",
        "    # saving this to PDT folder\n",
        "    np.save(training_metrics_npy_path, evaluation_metrics)\n",
        "\n",
        "    # Save parameters_list to CSV\n",
        "    parameters_csv_path = os.path.join(pdt_folder, \"top_parameters_list.csv\")\n",
        "    pd.DataFrame(parameters_list).to_csv(parameters_csv_path, index=False)\n",
        "\n",
        "    # Save parameters_list to NumPy\n",
        "    parameters_npy_path = os.path.join(pdt_folder, \"top_parameters_list.npy\")\n",
        "    np.save(parameters_npy_path, parameters_list)\n",
        "\n",
        "    # Save results_df to CSV\n",
        "    results_csv_path = os.path.join(pdt_folder, \"all_shuffleseed_with_depth.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "\n",
        "    # Save results_df to NumPy\n",
        "    results_npy_path = os.path.join(pdt_folder, \"all_shuffleseed_with_depth.npy\")\n",
        "    np.save(results_npy_path, results)\n",
        "\n",
        "    # Path for PDF csv file\n",
        "    pdf_metrics_csv_path = os.path.join(pdf_folder, \"evaluation_metrics_pdf_test.csv\")\n",
        "    # saving this to PDT folder\n",
        "    pd.DataFrame(evaluation_metrics_pdf.items(), columns=[\"Metric\", \"Value\"]).to_csv(pdf_metrics_csv_path, index=False)\n",
        "\n",
        "    # Path for PDF numpy file\n",
        "    pdf_metrics_npy_path = os.path.join(pdf_folder, \"evaluation_metrics_pdf_test.npy\")\n",
        "    #saving it to PDF folder\n",
        "    np.save(pdf_metrics_npy_path, evaluation_metrics_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRqVzPs-UyWX"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "# from sklearn.utils import shuffle\n",
        "\n",
        "# # Define the number of splits for time series split\n",
        "# num_splits = 5\n",
        "\n",
        "# # Fix the seed value for splitting data\n",
        "# split_seed = 42\n",
        "\n",
        "# # Define different seed values for shuffling training data\n",
        "# shuffle_seed_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "\n",
        "# # Define the range of depths for the decision tree\n",
        "# depth_range = range(2, 21)\n",
        "\n",
        "# # Initialize a list to store the results\n",
        "# results = []\n",
        "# # declaring test size for time series split\n",
        "# time_series_split_test_size = 15\n",
        "\n",
        "# # _______________________________________________________________________________\n",
        "\n",
        "# # Variable description:\n",
        "# # _______________________________________________________________________________\n",
        "\n",
        "# #     X               -   Data attributes.\n",
        "# #     y               -   Corresponding labels for X.\n",
        "# #     X_train         -   Data attributes for training (80% of the dataset).\n",
        "# #     y_train         -   Corresponding labels for X_train.\n",
        "# #     X_test          -   Data attributes for testing (20% of the dataset).\n",
        "# #     y_test          -   Corresponding labels for X_test.\n",
        "# # Split the data into training and testing sets with the fixed seed\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "# # Perform experiments for each seed value for shuffling training data\n",
        "# for shuffle_seed in shuffle_seed_values:\n",
        "#     # Shuffle only the training data with the current seed\n",
        "#     X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=shuffle_seed)\n",
        "\n",
        "#     # Perform time series split\n",
        "#     tscv = TimeSeriesSplit(n_splits=num_splits,test_size=time_series_split_test_size)\n",
        "\n",
        "#     # Iterate over different depths for the decision tree\n",
        "#     for depth in depth_range:\n",
        "#         # Initialize lists to store evaluation metrics for each fold\n",
        "#         accuracies = []\n",
        "#         f1_scores = []\n",
        "#         precisions = []\n",
        "#         recalls = []\n",
        "\n",
        "#         # Perform time series split\n",
        "#         for split_num, (train_index, test_index) in enumerate(tscv.split(X_train_shuffled), 1):\n",
        "#             X_cv_train, X_cv_test = X_train_shuffled[train_index], X_train_shuffled[test_index]\n",
        "#             y_cv_train, y_cv_test = y_train_shuffled[train_index], y_train_shuffled[test_index]\n",
        "\n",
        "#             # Train the decision tree model with the current depth\n",
        "#             tree_classifier = DecisionTreeClassifier(max_depth=depth)\n",
        "#             tree_classifier.fit(X_cv_train, y_cv_train)\n",
        "\n",
        "#             # Make predictions\n",
        "#             y_pred = tree_classifier.predict(X_cv_test)\n",
        "\n",
        "#             # Calculate evaluation metrics for this fold\n",
        "#             accuracy = accuracy_score(y_cv_test, y_pred)\n",
        "#             f1 = f1_score(y_cv_test, y_pred, average='macro')  # Use macro F1 score\n",
        "#             precision = precision_score(y_cv_test, y_pred, average='macro', zero_division = 1)\n",
        "#             recall = recall_score(y_cv_test, y_pred, average='macro', zero_division = 1)\n",
        "\n",
        "#             # Append metrics to the lists\n",
        "#             accuracies.append(accuracy)\n",
        "#             f1_scores.append(f1)\n",
        "#             precisions.append(precision)\n",
        "#             recalls.append(recall)\n",
        "\n",
        "#         # Calculate mean metrics across all folds\n",
        "#         mean_accuracy = sum(accuracies) / len(accuracies)\n",
        "#         mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "#         mean_precision = sum(precisions) / len(precisions)\n",
        "#         mean_recall = sum(recalls) / len(recalls)\n",
        "\n",
        "#         # Store the results for this seed value and depth\n",
        "#         results.append({\n",
        "#             'Split Seed': split_seed,\n",
        "#             'Shuffle Seed': shuffle_seed,\n",
        "#             'Depth of Tree': depth,\n",
        "#             'Mean Accuracy': mean_accuracy,\n",
        "#             'Mean F1 Score': mean_f1,\n",
        "#             'Mean Precision': mean_precision,\n",
        "#             'Mean Recall': mean_recall\n",
        "#         })\n",
        "\n",
        "# # Create a DataFrame from the results\n",
        "# results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAlrRNFsU-Q3",
        "outputId": "36fbfdfa-ae8a-4921-a23d-ab5069f4369e"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # Group by 'Shuffle Seed' and find the maximum F1 score within each group\n",
        "# max_f1_score_per_group = results_df.groupby('Shuffle Seed')['Mean F1 Score'].transform(max)\n",
        "\n",
        "# # Filter the DataFrame to keep rows where 'Mean F1 Score' is equal to the maximum F1 score within each group\n",
        "# max_f1_rows = results_df[results_df['Mean F1 Score'] == max_f1_score_per_group]\n",
        "\n",
        "# # Group the max_f1_rows DataFrame by 'Shuffle Seed' and find the row with the minimum 'Depth of Tree' within each group\n",
        "# min_depth_for_max_f1 = max_f1_rows.groupby('Shuffle Seed').apply(lambda x: x.loc[x['Depth of Tree'].idxmin()])\n",
        "\n",
        "# # Extracting desired columns\n",
        "# selected_columns = min_depth_for_max_f1[['Split Seed', 'Shuffle Seed', 'Depth of Tree']]\n",
        "\n",
        "# # # Printing the extracted values\n",
        "# # print(\"Shuffle seed values with corresponding depth for maximum F1 score:\")\n",
        "# # for _, row in selected_columns.iterrows():\n",
        "# #     print(f\"{{'Split Seed': {row['Split Seed']}, 'Shuffle Seed': {row['Shuffle Seed']}, 'Depth': {row['Depth of Tree']}}}\")\n",
        "\n",
        "# # Convert the selected columns to a numpy array and save it\n",
        "# parameters_array = selected_columns.to_numpy()\n",
        "\n",
        "# # Convert each row of the numpy array to a dictionary\n",
        "# parameters_list = [{'Split Seed': row[0], 'Shuffle Seed': row[1], 'Depth': row[2]} for row in parameters_array]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-E_pHPyU_Yu",
        "outputId": "688794d3-f6b0-4d88-ebe9-a2541e942331"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "# from sklearn.utils import shuffle\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import numpy as np\n",
        "\n",
        "# # Initialize a list to store the evaluation metrics for each model\n",
        "# evaluation_metrics = []\n",
        "\n",
        "# # Iterate over the top parameters\n",
        "# for i, params in enumerate(parameters_list, start=1):\n",
        "#     split_seed = int(params['Split Seed'])  # Convert to integer\n",
        "#     shuffle_seed = int(params['Shuffle Seed'])\n",
        "#     max_depth = int(params['Depth'])\n",
        "\n",
        "#     # Split the dataset\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "#     # Shuffle only the training data with the fixed seed\n",
        "#     X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=shuffle_seed)\n",
        "\n",
        "#     # Train the decision tree model with the entire training data\n",
        "#     tree_classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
        "#     tree_classifier.fit(X_train_shuffled, y_train_shuffled)\n",
        "\n",
        "#     #  # Printing the decision tree\n",
        "#     # print(f\"Model {i} Decision Tree:\")\n",
        "#     # tree_classifier.print_tree()\n",
        "#     # print()  # empty line for readability\n",
        "\n",
        "#     # Make predictions on the training data\n",
        "#     y_pred_train_data = tree_classifier.predict(X_train_shuffled)\n",
        "\n",
        "#     # Calculate evaluation metrics\n",
        "#     accuracy_train = accuracy_score(y_train_shuffled, y_pred_train_data)\n",
        "#     f1_train = f1_score(y_train_shuffled, y_pred_train_data, average='macro')\n",
        "#     precision_train = precision_score(y_train_shuffled, y_pred_train_data, average='macro',zero_division=1)\n",
        "\n",
        "#     # Append the evaluation metrics to the list\n",
        "#     evaluation_metrics.append({\n",
        "#         'Model': i,\n",
        "#         'Split Seed': split_seed,\n",
        "#         'Shuffle Seed': shuffle_seed,\n",
        "#         'Max Depth': max_depth,\n",
        "#         'Accuracy_train': accuracy_train,\n",
        "#         'F1 Score_train': f1_train,\n",
        "#         'Precision_train': precision_train\n",
        "#     })\n",
        "\n",
        "# # # Display the evaluation metrics for each model\n",
        "# # for metrics in evaluation_metrics:\n",
        "# #     print(f\"Model {metrics['Model']} Evaluation Metrics:\")\n",
        "# #     print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftN1VEWowpkF",
        "outputId": "f4851f02-4e64-40aa-dd58-258b98626251"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# # Find the row with the maximum F1 score\n",
        "# max_f1_row = results_df.loc[results_df['Mean F1 Score'].idxmax()]\n",
        "\n",
        "# # Extract the shuffle seed value with maximum F1 score\n",
        "# shuffle_seed_with_max_f1_score = max_f1_row['Shuffle Seed']\n",
        "\n",
        "# # Find the index of the row with shuffle_seed_with_max_f1_score in parameters list\n",
        "# max_f1_index = None\n",
        "# for idx, params in enumerate(parameters_list):\n",
        "#     if params['Shuffle Seed'] == shuffle_seed_with_max_f1_score:\n",
        "#         max_f1_index = idx\n",
        "#         break\n",
        "\n",
        "# if max_f1_index is not None:\n",
        "#     max_f1_params = parameters_list[max_f1_index]\n",
        "\n",
        "# # Finding the depth corresponding to the shuffle seed value\n",
        "# corresponding_depth = max_f1_params['Depth']\n",
        "\n",
        "# # # Print the chosen shuffle seed value\n",
        "# # print(\"Chosen Shuffle Seed for Training:\", shuffle_seed_with_max_f1_score)\n",
        "# # print(\"Corresponding depth:\", corresponding_depth)\n",
        "\n",
        "# # Split the data into training and testing sets using the chosen shuffle seed value\n",
        "# X_train_pdt, X_test_pdt, y_train_pdt, y_test_pdt = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "# # Shuffle only the training data with the chosen shuffle seed value\n",
        "# X_train_shuffled_pdt, y_train_shuffled_pdt = shuffle(X_train_pdt, y_train_pdt, random_state=int(shuffle_seed_with_max_f1_score))\n",
        "\n",
        "# # Train a decision tree classifier with the chosen depth\n",
        "# classifier_pdt = DecisionTreeClassifier(max_depth=corresponding_depth)\n",
        "# classifier_pdt.fit(X_train_shuffled_pdt, y_train_shuffled_pdt)\n",
        "\n",
        "# # Predict labels for the testing data\n",
        "# y_pred_pdt = classifier_pdt.predict(X_test_pdt)\n",
        "\n",
        "# # Calculate evaluation metrics\n",
        "# accuracy_pdt = accuracy_score(y_test_pdt, y_pred_pdt)\n",
        "# f1_score_pdt = f1_score(y_test_pdt, y_pred_pdt, average='macro')\n",
        "# precision_pdt = precision_score(y_test_pdt, y_pred_pdt, average='macro', zero_division=1)\n",
        "# recall_pdt = recall_score(y_test_pdt, y_pred_pdt, average='macro', zero_division=1)\n",
        "\n",
        "# # Print the evaluation metrics\n",
        "# print(\"Evaluation Metrics:\")\n",
        "# print(f\"Accuracy: {accuracy_pdt}\")\n",
        "# print(f\"F1 Score: {f1_score_pdt}\")\n",
        "# print(f\"Precision: {precision_pdt}\")\n",
        "# print(f\"Recall: {recall_pdt}\")\n",
        "\n",
        "# # Creating this because we want to save the result in form of csv and numpy\n",
        "# evaluation_metrics_pdt = {\n",
        "#     \"Accuracy\": accuracy_pdt,\n",
        "#     \"F1 Score\": f1_score_pdt,\n",
        "#     \"Precision\": precision_pdt,\n",
        "#     \"Recall\": recall_pdt\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0wmB095VKii",
        "outputId": "b1b296a3-2d54-4156-e846-aa83f9acfefd"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "# from sklearn.utils import shuffle\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Initialize a list to store the top shuffle seeds along with their corresponding depths\n",
        "# top_shuffle_seeds = []\n",
        "\n",
        "# # Iterate over the top parameters\n",
        "# for params in parameters_list:\n",
        "#     split_seed = int(params['Split Seed'])\n",
        "#     shuffle_seed = int(params['Shuffle Seed'])\n",
        "#     depth = int(params['Depth'])\n",
        "#     top_shuffle_seeds.append({'Split Seed':split_seed, 'Shuffle Seed': shuffle_seed, 'Depth': depth})\n",
        "\n",
        "# # Load the dataset\n",
        "# X_train_pdf, X_test_pdf, y_train_pdf, y_test_pdf = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "# # Create an empty matrix to store predictions\n",
        "# predictions_matrix = np.zeros((len(X_test), len(top_shuffle_seeds)), dtype=int)\n",
        "\n",
        "# # Iterate over each test sample\n",
        "# # for i, x_test_sample in enumerate(X_test):\n",
        "#     # Make predictions using each model\n",
        "# for j, params in enumerate(top_shuffle_seeds):\n",
        "#     split_seed = (params['Split Seed'])\n",
        "#     shuffle_seed = params['Shuffle Seed']\n",
        "#     max_depth = params['Depth']\n",
        "\n",
        "#     # Shuffle only the training data with the fixed seed\n",
        "#     X_train_shuffled_pdf, y_train_shuffled_pdf = shuffle(X_train_pdf, y_train_pdf, random_state=shuffle_seed)\n",
        "\n",
        "#     # Train the decision tree model with the entire training data\n",
        "#     tree_classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
        "#     tree_classifier.fit(X_train_shuffled_pdf, y_train_shuffled_pdf)\n",
        "\n",
        "#     # Make prediction for the current test sample using the trained model\n",
        "#     prediction = tree_classifier.predict(X_test_pdf)\n",
        "\n",
        "#     # Store the prediction in the matrix\n",
        "#     predictions_matrix[:, j] = prediction\n",
        "\n",
        "# # Initialize lists to store final predictions and evaluation metrics\n",
        "# final_predictions = []\n",
        "# accuracies = []\n",
        "# precisions = []\n",
        "# f1_scores = []\n",
        "\n",
        "# # Iterate over each row in the predictions matrix\n",
        "# for i in range(predictions_matrix.shape[0]):\n",
        "#     # Find the majority occurring element in the row\n",
        "#     majority_prediction = np.bincount(predictions_matrix[i,:]).argmax()\n",
        "\n",
        "#     # Append the majority prediction to the final predictions list\n",
        "#     final_predictions.append(majority_prediction)\n",
        "# final_prediction = predictions_matrix[:,-1]\n",
        "# # Calculate accuracy, precision, F1-score and recall using the majority prediction and actual test label\n",
        "# accuracy_test_pdf = accuracy_score(y_test_pdf, final_predictions)\n",
        "# precision_test_pdf = precision_score(y_test_pdf, final_predictions, average='macro', zero_division=1)\n",
        "# f1_test_pdf = f1_score(y_test_pdf, final_predictions, average='macro')\n",
        "# recall_test_pdf = recall_score(y_test_pdf, final_predictions, average='macro', zero_division=1)\n",
        "\n",
        "\n",
        "\n",
        "# # Print the final evaluation metrics\n",
        "# print(\"Overall Evaluation Metrics:\")\n",
        "# print(f\"Accuracy_test_pdf: {accuracy_test_pdf}\")\n",
        "# print(f\"Precision_test_pdf: {precision_test_pdf}\")\n",
        "# print(f\"F1 Score_test_pdf: {f1_test_pdf}\")\n",
        "# print(f\"Recall_test_pdf: {recall_test_pdf}\")\n",
        "\n",
        "# # Creating this because we want to save the result in form of csv and numpy\n",
        "# evaluation_metrics_pdf = {\n",
        "#     \"Accuracy\": accuracy_test_pdf,\n",
        "#     \"F1 Score\": f1_test_pdf,\n",
        "#     \"Precision\": precision_test_pdf,\n",
        "#     \"Recall\": recall_test_pdf\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc98URuzPngC"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# # Get the current working directory\n",
        "# current_directory = os.getcwd()\n",
        "\n",
        "# # Define the path to the results folder\n",
        "# results_folder = os.path.join(current_directory, \"results\")\n",
        "\n",
        "# # Define the dataset name\n",
        "# dataset_name = dataset_name\n",
        "\n",
        "# # Create a folder for the current dataset within the results directory\n",
        "# dataset_results_folder = os.path.join(results_folder, dataset_name)\n",
        "# os.makedirs(dataset_results_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "# # Create folders for PDT and pdf within the dataset results folder\n",
        "# pdt_folder = os.path.join(dataset_results_folder, \"PDT\")\n",
        "# pdf_folder = os.path.join(dataset_results_folder, \"PDF\")\n",
        "# os.makedirs(pdt_folder, exist_ok=True)\n",
        "# os.makedirs(pdf_folder, exist_ok=True)\n",
        "\n",
        "# # Path for PDT csv file\n",
        "# pdt_metrics_csv_path = os.path.join(pdt_folder, \"evaluation_metrics_pdt_test.csv\")\n",
        "# # saving this to PDT folder\n",
        "# pd.DataFrame(evaluation_metrics_pdt.items(), columns=[\"Metric\", \"Value\"]).to_csv(pdt_metrics_csv_path, index=False)\n",
        "\n",
        "# # Path for PDT numpy file\n",
        "# pdt_metrics_npy_path = os.path.join(pdt_folder, \"evaluation_metrics_pdt_test.npy\")\n",
        "# #saving it to PDT folder\n",
        "# np.save(pdt_metrics_npy_path, evaluation_metrics_pdt)\n",
        "\n",
        "# # Save parameters_list to CSV\n",
        "# parameters_csv_path = os.path.join(pdt_folder, \"top_parameters_list.csv\")\n",
        "# pd.DataFrame(parameters_list).to_csv(parameters_csv_path, index=False)\n",
        "\n",
        "# # Save parameters_list to NumPy\n",
        "# parameters_npy_path = os.path.join(pdt_folder, \"top_parameters_list.npy\")\n",
        "# np.save(parameters_npy_path, parameters_list)\n",
        "\n",
        "# # Save results_df to CSV\n",
        "# results_csv_path = os.path.join(pdt_folder, \"all_shuffleseed_with_depth.csv\")\n",
        "# results_df.to_csv(results_csv_path, index=False)\n",
        "\n",
        "# # Save results_df to NumPy\n",
        "# results_npy_path = os.path.join(pdt_folder, \"all_shuffleseed_with_depth.npy\")\n",
        "# np.save(results_npy_path, results)\n",
        "\n",
        "# # Path for PDF csv file\n",
        "# pdf_metrics_csv_path = os.path.join(pdf_folder, \"evaluation_metrics_pdf_test.csv\")\n",
        "# # saving this to PDT folder\n",
        "# pd.DataFrame(evaluation_metrics_pdf.items(), columns=[\"Metric\", \"Value\"]).to_csv(pdf_metrics_csv_path, index=False)\n",
        "\n",
        "# # Path for PDF numpy file\n",
        "# pdf_metrics_npy_path = os.path.join(pdf_folder, \"evaluation_metrics_pdf_test.npy\")\n",
        "# #saving it to PDF folder\n",
        "# np.save(pdf_metrics_npy_path, evaluation_metrics_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
