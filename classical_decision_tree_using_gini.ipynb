{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8XB9jN4cU1Mn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ionosphere\n",
            "3.0\n",
            "DecisionTreeClassifier(max_depth=3, random_state=21)\n",
            "Test Accuracy: 0.8591549295774648\n",
            "Test F1 Score: 0.8426418439716312\n",
            "Test Precision: 0.8867647058823529\n",
            "Test Recall: 0.8276578073089701\n",
            "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33],\n",
            "      dtype='int64')\n",
            "|--- 4 <= 0.04\n",
            "|   |--- class: 0\n",
            "|--- 4 >  0.04\n",
            "|   |--- 26 <= 1.00\n",
            "|   |   |--- 2 <= 0.14\n",
            "|   |   |   |--- class: 0\n",
            "|   |   |--- 2 >  0.14\n",
            "|   |   |   |--- class: 1\n",
            "|   |--- 26 >  1.00\n",
            "|   |   |--- 21 <= -0.07\n",
            "|   |   |   |--- class: 1\n",
            "|   |   |--- 21 >  -0.07\n",
            "|   |   |   |--- class: 0\n",
            "\n",
            "iris\n",
            "2.0\n",
            "DecisionTreeClassifier(max_depth=2, random_state=21)\n",
            "Test Accuracy: 0.9666666666666667\n",
            "Test F1 Score: 0.9658994032395567\n",
            "Test Precision: 0.9722222222222222\n",
            "Test Recall: 0.9629629629629629\n",
            "Index([0, 1, 2, 3], dtype='int64')\n",
            "|--- 3 <= 0.80\n",
            "|   |--- class: 0\n",
            "|--- 3 >  0.80\n",
            "|   |--- 2 <= 4.75\n",
            "|   |   |--- class: 1\n",
            "|   |--- 2 >  4.75\n",
            "|   |   |--- class: 2\n",
            "\n",
            "breastcancerwisconsin\n",
            "4.0\n",
            "DecisionTreeClassifier(max_depth=4, random_state=21)\n",
            "Test Accuracy: 0.9473684210526315\n",
            "Test F1 Score: 0.9439895185063871\n",
            "Test Precision: 0.9439895185063871\n",
            "Test Recall: 0.9439895185063871\n",
            "Index([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
            "       20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
            "      dtype='int64')\n",
            "|--- 9 <= 0.05\n",
            "|   |--- 22 <= 16.83\n",
            "|   |   |--- 15 <= 48.70\n",
            "|   |   |   |--- 26 <= 0.18\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 26 >  0.18\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- 15 >  48.70\n",
            "|   |   |   |--- 16 <= 0.01\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 16 >  0.01\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |--- 22 >  16.83\n",
            "|   |   |--- 23 <= 19.91\n",
            "|   |   |   |--- class: 1\n",
            "|   |   |--- 23 >  19.91\n",
            "|   |   |   |--- 19 <= 0.01\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |   |--- 19 >  0.01\n",
            "|   |   |   |   |--- class: 1\n",
            "|--- 9 >  0.05\n",
            "|   |--- 29 <= 0.15\n",
            "|   |   |--- 24 <= 115.25\n",
            "|   |   |   |--- 3 <= 21.06\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 3 >  21.06\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- 24 >  115.25\n",
            "|   |   |   |--- class: 0\n",
            "|   |--- 29 >  0.15\n",
            "|   |   |--- 18 <= 0.14\n",
            "|   |   |   |--- class: 0\n",
            "|   |   |--- 18 >  0.14\n",
            "|   |   |   |--- class: 1\n",
            "\n",
            "wine\n",
            "4.0\n",
            "DecisionTreeClassifier(max_depth=4, random_state=21)\n",
            "Test Accuracy: 0.9444444444444444\n",
            "Test F1 Score: 0.94320987654321\n",
            "Test Precision: 0.9583333333333334\n",
            "Test Recall: 0.9345238095238096\n",
            "Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int64')\n",
            "|--- 10 <= 3.82\n",
            "|   |--- 13 <= 1002.50\n",
            "|   |   |--- 3 <= 3.07\n",
            "|   |   |   |--- class: 1\n",
            "|   |   |--- 3 >  3.07\n",
            "|   |   |   |--- class: 0\n",
            "|   |--- 13 >  1002.50\n",
            "|   |   |--- class: 0\n",
            "|--- 10 >  3.82\n",
            "|   |--- 7 <= 1.40\n",
            "|   |   |--- class: 2\n",
            "|   |--- 7 >  1.40\n",
            "|   |   |--- 13 <= 724.50\n",
            "|   |   |   |--- 2 <= 3.92\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 2 >  3.92\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- 13 >  724.50\n",
            "|   |   |   |--- class: 0\n",
            "\n",
            "diabetespimaindian\n",
            "7.0\n",
            "DecisionTreeClassifier(max_depth=7, random_state=21)\n",
            "Test Accuracy: 0.8441558441558441\n",
            "Test F1 Score: 0.8328811720021704\n",
            "Test Precision: 0.8287243532560213\n",
            "Test Recall: 0.8383838383838385\n",
            "Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64')\n",
            "|--- 4 <= 121.00\n",
            "|   |--- 1 <= 151.50\n",
            "|   |   |--- 0 <= 14.00\n",
            "|   |   |   |--- 5 <= 50.90\n",
            "|   |   |   |   |--- 6 <= 0.75\n",
            "|   |   |   |   |   |--- 4 <= 113.00\n",
            "|   |   |   |   |   |   |--- 4 <= 98.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- 4 >  98.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 4 >  113.00\n",
            "|   |   |   |   |   |   |--- 0 <= 7.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- 0 >  7.00\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- 6 >  0.75\n",
            "|   |   |   |   |   |--- 5 <= 31.80\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 5 >  31.80\n",
            "|   |   |   |   |   |   |--- 5 <= 38.10\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- 5 >  38.10\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- 5 >  50.90\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- 0 >  14.00\n",
            "|   |   |   |--- class: 1\n",
            "|   |--- 1 >  151.50\n",
            "|   |   |--- 3 <= 31.50\n",
            "|   |   |   |--- 7 <= 36.00\n",
            "|   |   |   |   |--- 4 <= 80.00\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 4 >  80.00\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 7 >  36.00\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- 3 >  31.50\n",
            "|   |   |   |--- class: 1\n",
            "|--- 4 >  121.00\n",
            "|   |--- 7 <= 28.50\n",
            "|   |   |--- 3 <= 30.50\n",
            "|   |   |   |--- 5 <= 37.80\n",
            "|   |   |   |   |--- 0 <= 0.50\n",
            "|   |   |   |   |   |--- 6 <= 0.60\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 6 >  0.60\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- 0 >  0.50\n",
            "|   |   |   |   |   |--- 0 <= 2.50\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 0 >  2.50\n",
            "|   |   |   |   |   |   |--- 3 <= 23.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- 3 >  23.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- 5 >  37.80\n",
            "|   |   |   |   |--- 1 <= 149.00\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 1 >  149.00\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |--- 3 >  30.50\n",
            "|   |   |   |--- 4 <= 169.75\n",
            "|   |   |   |   |--- 4 <= 158.50\n",
            "|   |   |   |   |   |--- 4 <= 137.50\n",
            "|   |   |   |   |   |   |--- 2 <= 76.00\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- 2 >  76.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 4 >  137.50\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 4 >  158.50\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 4 >  169.75\n",
            "|   |   |   |   |--- 1 <= 169.00\n",
            "|   |   |   |   |   |--- 2 <= 54.00\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- 2 >  54.00\n",
            "|   |   |   |   |   |   |--- 3 <= 41.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- 3 >  41.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 1 >  169.00\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |--- 7 >  28.50\n",
            "|   |   |--- 4 <= 142.00\n",
            "|   |   |   |--- 2 <= 65.00\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |   |--- 2 >  65.00\n",
            "|   |   |   |   |--- 5 <= 39.55\n",
            "|   |   |   |   |   |--- 3 <= 16.50\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 3 >  16.50\n",
            "|   |   |   |   |   |   |--- 7 <= 49.00\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- 7 >  49.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 5 >  39.55\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |--- 4 >  142.00\n",
            "|   |   |   |--- 4 <= 187.00\n",
            "|   |   |   |   |--- 3 <= 16.00\n",
            "|   |   |   |   |   |--- 5 <= 31.00\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- 5 >  31.00\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 3 >  16.00\n",
            "|   |   |   |   |   |--- 4 <= 168.75\n",
            "|   |   |   |   |   |   |--- 4 <= 166.50\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- 4 >  166.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- 4 >  168.75\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 4 >  187.00\n",
            "|   |   |   |   |--- 1 <= 157.50\n",
            "|   |   |   |   |   |--- 2 <= 75.00\n",
            "|   |   |   |   |   |   |--- 0 <= 7.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- 0 >  7.50\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- 2 >  75.00\n",
            "|   |   |   |   |   |   |--- 1 <= 153.00\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- 1 >  153.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 1 >  157.50\n",
            "|   |   |   |   |   |--- 6 <= 1.68\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- 6 >  1.68\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "\n",
            "sonar\n",
            "5.0\n",
            "DecisionTreeClassifier(max_depth=5, random_state=21)\n",
            "Test Accuracy: 0.6666666666666666\n",
            "Test F1 Score: 0.6597222222222223\n",
            "Test Precision: 0.6613636363636364\n",
            "Test Recall: 0.6706730769230769\n",
            "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "       54, 55, 56, 57, 58, 59],\n",
            "      dtype='int64')\n",
            "|--- 10 <= 0.20\n",
            "|   |--- 3 <= 0.05\n",
            "|   |   |--- 52 <= 0.00\n",
            "|   |   |   |--- class: 1\n",
            "|   |   |--- 52 >  0.00\n",
            "|   |   |   |--- 51 <= 0.03\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |   |--- 51 >  0.03\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |--- 3 >  0.05\n",
            "|   |   |--- 58 <= 0.01\n",
            "|   |   |   |--- class: 0\n",
            "|   |   |--- 58 >  0.01\n",
            "|   |   |   |--- 36 <= 0.79\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 36 >  0.79\n",
            "|   |   |   |   |--- class: 0\n",
            "|--- 10 >  0.20\n",
            "|   |--- 15 <= 0.67\n",
            "|   |   |--- 25 <= 0.28\n",
            "|   |   |   |--- class: 0\n",
            "|   |   |--- 25 >  0.28\n",
            "|   |   |   |--- 32 <= 0.15\n",
            "|   |   |   |   |--- 4 <= 0.12\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 4 >  0.12\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 32 >  0.15\n",
            "|   |   |   |   |--- 8 <= 0.07\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- 8 >  0.07\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |--- 15 >  0.67\n",
            "|   |   |--- 30 <= 0.40\n",
            "|   |   |   |--- 18 <= 0.85\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |   |--- 18 >  0.85\n",
            "|   |   |   |   |--- 40 <= 0.34\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- 40 >  0.34\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |--- 30 >  0.40\n",
            "|   |   |   |--- class: 0\n",
            "\n",
            "appendicitis\n",
            "2.0\n",
            "DecisionTreeClassifier(max_depth=2, random_state=21)\n",
            "Test Accuracy: 0.7727272727272727\n",
            "Test F1 Score: 0.6507936507936507\n",
            "Test Precision: 0.7280701754385965\n",
            "Test Recall: 0.6354166666666666\n",
            "Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')\n",
            "|--- 6 <= 0.15\n",
            "|   |--- 3 <= 0.48\n",
            "|   |   |--- class: 1\n",
            "|   |--- 3 >  0.48\n",
            "|   |   |--- class: 0\n",
            "|--- 6 >  0.15\n",
            "|   |--- 5 <= 0.74\n",
            "|   |   |--- class: 0\n",
            "|   |--- 5 >  0.74\n",
            "|   |   |--- class: 0\n",
            "\n",
            "nyse_stock_data.data\n",
            "5.0\n",
            "DecisionTreeClassifier(max_depth=5, random_state=21)\n",
            "Test Accuracy: 0.9721362229102167\n",
            "Test F1 Score: 0.9353128147927082\n",
            "Test Precision: 0.9267438998801841\n",
            "Test Recall: 0.949525287196912\n",
            "Index([1, 2, 3, 5], dtype='int64')\n",
            "|--- 2 <= 40.30\n",
            "|   |--- 3 <= 39.76\n",
            "|   |   |--- class: 0\n",
            "|   |--- 3 >  39.76\n",
            "|   |   |--- 2 <= 40.20\n",
            "|   |   |   |--- class: 0\n",
            "|   |   |--- 2 >  40.20\n",
            "|   |   |   |--- class: 1\n",
            "|--- 2 >  40.30\n",
            "|   |--- 3 <= 58.97\n",
            "|   |   |--- 3 <= 39.19\n",
            "|   |   |   |--- 5 <= 281964592.00\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- 5 >  281964592.00\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- 3 >  39.19\n",
            "|   |   |   |--- class: 1\n",
            "|   |--- 3 >  58.97\n",
            "|   |   |--- 2 <= 80.84\n",
            "|   |   |   |--- 2 <= 80.34\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- 2 >  80.34\n",
            "|   |   |   |   |--- 2 <= 80.63\n",
            "|   |   |   |   |   |--- class: 3\n",
            "|   |   |   |   |--- 2 >  80.63\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |--- 2 >  80.84\n",
            "|   |   |   |--- 2 <= 126.58\n",
            "|   |   |   |   |--- 2 <= 103.19\n",
            "|   |   |   |   |   |--- class: 3\n",
            "|   |   |   |   |--- 2 >  103.19\n",
            "|   |   |   |   |   |--- class: 4\n",
            "|   |   |   |--- 2 >  126.58\n",
            "|   |   |   |   |--- 5 <= 225070552.00\n",
            "|   |   |   |   |   |--- class: 5\n",
            "|   |   |   |   |--- 5 >  225070552.00\n",
            "|   |   |   |   |   |--- class: 4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# importing dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import os\n",
        "from load import load\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "# Define the path to the datasets folder\n",
        "datasets_folder = os.path.join(current_directory, \"datasets\")\n",
        "exclude_datasets = ['rice', 'timeseries.py', 'analysis.py', 'normalized_nyse_stock_data.data', 'pca_normalized_nyse_stock_data.data', 'media.data', 'reliance.data']\n",
        "datasets = [dataset for dataset in os.listdir(datasets_folder) if not (dataset.startswith('.') or dataset in exclude_datasets)]\n",
        "\n",
        "for dataset_name in datasets:\n",
        "    # importing dataset\n",
        "    print(dataset_name)\n",
        "    X, Y = load(dataset_name)\n",
        "    # Define the number of splits for time series split\n",
        "    num_splits = 5\n",
        "\n",
        "    # Fix the seed value for splitting data\n",
        "    split_seed = 42\n",
        "\n",
        "    # Define the range of depths for the decision tree\n",
        "    depth_range = range(2, 21)\n",
        "\n",
        "    # Initialize a list to store the results\n",
        "    results = []\n",
        "\n",
        "    # declaring test size for time series split\n",
        "    time_series_split_test_size = 15\n",
        "\n",
        "    # _______________________________________________________________________________\n",
        "\n",
        "    # Variable description:\n",
        "    # _______________________________________________________________________________\n",
        "\n",
        "    #     X               -   Data attributes.for X_train.\n",
        "    #     X_test          -   Data attributes for testing (20% of the dataset).\n",
        "    #     y_test          -   Corresponding labels for X_test.\n",
        "\n",
        "    # Split the data into training and testing sets with the fixed seed\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "    # Perform time series split\n",
        "    tscv = TimeSeriesSplit(n_splits=num_splits, test_size=time_series_split_test_size)\n",
        "\n",
        "    # Iterate over different depths for the decision tree\n",
        "    for depth in depth_range:\n",
        "        # Initialize lists to store evaluation metrics for each fold\n",
        "        accuracies = []\n",
        "        f1_scores = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "\n",
        "        # Perform time series split\n",
        "        for split_num, (train_index, test_index) in enumerate(tscv.split(X_train), 1):\n",
        "            X_cv_train, X_cv_test = pd.DataFrame(X_train).iloc[train_index], pd.DataFrame(X_train).iloc[test_index]\n",
        "            y_cv_train, y_cv_test = pd.DataFrame(y_train).iloc[train_index], pd.DataFrame(y_train).iloc[test_index]\n",
        "\n",
        "            # Train the decision tree model with the current depth\n",
        "            tree_classifier = DecisionTreeClassifier(criterion='gini',max_depth=depth, random_state= 21)\n",
        "            tree_classifier.fit(X_cv_train, y_cv_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = tree_classifier.predict(X_cv_test)\n",
        "\n",
        "            # Calculate evaluation metrics for this fold\n",
        "            accuracy = accuracy_score(y_cv_test, y_pred)\n",
        "            f1 = f1_score(y_cv_test, y_pred, average='macro')  # Use macro F1 score\n",
        "            precision = precision_score(y_cv_test, y_pred, average='macro', zero_division=1)\n",
        "            recall = recall_score(y_cv_test, y_pred, average='macro', zero_division=1)\n",
        "\n",
        "            # Append metrics to the lists\n",
        "            accuracies.append(accuracy)\n",
        "            f1_scores.append(f1)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "\n",
        "        # Calculate mean metrics across all folds\n",
        "        mean_accuracy = sum(accuracies) / len(accuracies)\n",
        "        mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "        mean_precision = sum(precisions) / len(precisions)\n",
        "        mean_recall = sum(recalls) / len(recalls)\n",
        "\n",
        "        # Store the results for this depth\n",
        "        results.append({\n",
        "            'Split Seed': split_seed,\n",
        "            'Depth of Tree': depth,\n",
        "            'Mean Accuracy': mean_accuracy,\n",
        "            'Mean F1 Score': mean_f1,\n",
        "            'Mean Precision': mean_precision,\n",
        "            'Mean Recall': mean_recall\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Find the depth with the maximum F1 score\n",
        "    best_depth_row = results_df.loc[results_df['Mean F1 Score'].idxmax()]\n",
        "\n",
        "    # Train the decision tree with the best depth on the entire training data\n",
        "    best_depth = best_depth_row['Depth of Tree']\n",
        "    print(best_depth)\n",
        "    best_tree_classifier = DecisionTreeClassifier(criterion='gini',max_depth=int(best_depth), random_state= 21)\n",
        "    best_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred_test_dt = best_tree_classifier.predict(X_test)\n",
        "    print(best_tree_classifier)\n",
        "    # Calculate evaluation metrics on the test data\n",
        "    accuracy_test_dt = accuracy_score(y_test, y_pred_test_dt)\n",
        "    f1_test_dt = f1_score(y_test, y_pred_test_dt, average='macro')\n",
        "    precision_test_dt = precision_score(y_test, y_pred_test_dt, average='macro', zero_division=1)\n",
        "    recall_test_dt = recall_score(y_test, y_pred_test_dt, average='macro', zero_division=1)\n",
        "\n",
        "    # Print the evaluation metrics on the test data\n",
        "    print(\"Test Accuracy:\", accuracy_test_dt)\n",
        "    print(\"Test F1 Score:\", f1_test_dt)\n",
        "    print(\"Test Precision:\", precision_test_dt)\n",
        "    print(\"Test Recall:\", recall_test_dt)\n",
        "\n",
        "    #print tree\n",
        "    from sklearn.tree import export_text\n",
        "    # Print the tree using export_text\n",
        "    tree_text = export_text(best_tree_classifier, feature_names=list(X.columns))\n",
        "    print(X.columns)\n",
        "    print(tree_text)\n",
        "\n",
        "    # Creating this because we want to save the result in form of csv and numpy\n",
        "    evaluation_metrics_dt_test = {\n",
        "        \"Accuracy\": accuracy_test_dt,\n",
        "        \"F1 Score\": f1_test_dt,\n",
        "        \"Precision\": precision_test_dt,\n",
        "        \"Recall\": recall_test_dt,\n",
        "        \"Depth\" : best_depth\n",
        "    }\n",
        "        # Define the path to the results folder\n",
        "    results_folder = os.path.join(current_directory, \"results\")\n",
        "\n",
        "    # Define the dataset name\n",
        "    dataset_name = dataset_name\n",
        "\n",
        "    # Create a folder for the current dataset within the results directory\n",
        "    dataset_results_folder = os.path.join(results_folder, dataset_name)\n",
        "    os.makedirs(dataset_results_folder, exist_ok=True)\n",
        "\n",
        "    # Create folder for decision tree results\n",
        "    dt_folder = os.path.join(dataset_results_folder, \"DT_gini\")\n",
        "    os.makedirs(dt_folder, exist_ok=True)\n",
        "    # Save results_df to CSV\n",
        "    results_csv_path = os.path.join(dt_folder, \"all_splitseed_with_depth.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "\n",
        "    # Save results_df to NumPy\n",
        "    results_npy_path = os.path.join(dt_folder, \"all_splitseed_with_depth.npy\")\n",
        "    np.save(results_npy_path, results)\n",
        "\n",
        "    # Path for DT csv file\n",
        "    dt_metrics_csv_path = os.path.join(dt_folder, \"evaluation_metrics_dt_test.csv\")\n",
        "    # saving this to DT folder\n",
        "    pd.DataFrame(evaluation_metrics_dt_test.items(), columns=[\"Metric\", \"Value\"]).to_csv(dt_metrics_csv_path, index=False)\n",
        "\n",
        "    # Path for DT numpy file\n",
        "    dt_metrics_npy_path = os.path.join(dt_folder, \"evaluation_metrics_dt_test.npy\")\n",
        "    # saving it to DT folder\n",
        "    np.save(dt_metrics_npy_path, evaluation_metrics_dt_test)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # importing dataset\n",
        "# from load import load\n",
        "# X, Y = load(\"breastcancerwisconsin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VfkhtQGKWaJU"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# # Define the number of splits for time series split\n",
        "# num_splits = 5\n",
        "\n",
        "# # Fix the seed value for splitting data\n",
        "# split_seed = 42\n",
        "\n",
        "# # Define the range of depths for the decision tree\n",
        "# depth_range = range(2, 21)\n",
        "\n",
        "# # Initialize a list to store the results\n",
        "# results = []\n",
        "\n",
        "# # declaring test size for time series split\n",
        "# time_series_split_test_size = 15\n",
        "\n",
        "# # _______________________________________________________________________________\n",
        "\n",
        "# # Variable description:\n",
        "# # _______________________________________________________________________________\n",
        "\n",
        "# #     X               -   Data attributes.\n",
        "# #     y               -   Corresponding labels for X.\n",
        "# #     X_train         -   Data attributes for training (80% of the dataset).\n",
        "# #     y_train         -   Corresponding labels for X_train.\n",
        "# #     X_test          -   Data attributes for testing (20% of the dataset).\n",
        "# #     y_test          -   Corresponding labels for X_test.\n",
        "\n",
        "# # Split the data into training and testing sets with the fixed seed\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "# # Perform time series split\n",
        "# tscv = TimeSeriesSplit(n_splits=num_splits, test_size=time_series_split_test_size)\n",
        "\n",
        "# # Iterate over different depths for the decision tree\n",
        "# for depth in depth_range:\n",
        "#     # Initialize lists to store evaluation metrics for each fold\n",
        "#     accuracies = []\n",
        "#     f1_scores = []\n",
        "#     precisions = []\n",
        "#     recalls = []\n",
        "\n",
        "#     # Perform time series split\n",
        "#     for split_num, (train_index, test_index) in enumerate(tscv.split(X_train), 1):\n",
        "#         X_cv_train, X_cv_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "#         y_cv_train, y_cv_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "#         # Train the decision tree model with the current depth\n",
        "#         tree_classifier = DecisionTreeClassifier(max_depth=depth)\n",
        "#         tree_classifier.fit(X_cv_train, y_cv_train)\n",
        "\n",
        "#         # Make predictions\n",
        "#         y_pred = tree_classifier.predict(X_cv_test)\n",
        "\n",
        "#         # Calculate evaluation metrics for this fold\n",
        "#         accuracy = accuracy_score(y_cv_test, y_pred)\n",
        "#         f1 = f1_score(y_cv_test, y_pred, average='macro')  # Use macro F1 score\n",
        "#         precision = precision_score(y_cv_test, y_pred, average='macro', zero_division=1)\n",
        "#         recall = recall_score(y_cv_test, y_pred, average='macro', zero_division=1)\n",
        "\n",
        "#         # Append metrics to the lists\n",
        "#         accuracies.append(accuracy)\n",
        "#         f1_scores.append(f1)\n",
        "#         precisions.append(precision)\n",
        "#         recalls.append(recall)\n",
        "\n",
        "#     # Calculate mean metrics across all folds\n",
        "#     mean_accuracy = sum(accuracies) / len(accuracies)\n",
        "#     mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "#     mean_precision = sum(precisions) / len(precisions)\n",
        "#     mean_recall = sum(recalls) / len(recalls)\n",
        "\n",
        "#     # Store the results for this depth\n",
        "#     results.append({\n",
        "#         'Split Seed': split_seed,\n",
        "#         'Depth of Tree': depth,\n",
        "#         'Mean Accuracy': mean_accuracy,\n",
        "#         'Mean F1 Score': mean_f1,\n",
        "#         'Mean Precision': mean_precision,\n",
        "#         'Mean Recall': mean_recall\n",
        "#     })\n",
        "\n",
        "# # Create a DataFrame from the results\n",
        "# results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GAnc30X1u63",
        "outputId": "4fa4e66e-98b6-4bd7-b46c-71b7421366d9"
      },
      "outputs": [],
      "source": [
        "# # Find the depth with the maximum F1 score\n",
        "# best_depth_row = results_df.loc[results_df['Mean F1 Score'].idxmax()]\n",
        "\n",
        "# # Train the decision tree with the best depth on the entire training data\n",
        "# best_depth = best_depth_row['Depth of Tree']\n",
        "# print(best_depth)\n",
        "# best_tree_classifier = DecisionTreeClassifier(max_depth=int(best_depth))\n",
        "# best_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test data\n",
        "# y_pred_test_dt = best_tree_classifier.predict(X_test)\n",
        "\n",
        "# # Calculate evaluation metrics on the test data\n",
        "# accuracy_test_dt = accuracy_score(y_test, y_pred_test_dt)\n",
        "# f1_test_dt = f1_score(y_test, y_pred_test_dt, average='macro')\n",
        "# precision_test_dt = precision_score(y_test, y_pred_test_dt, average='macro', zero_division=1)\n",
        "# recall_test_dt = recall_score(y_test, y_pred_test_dt, average='macro', zero_division=1)\n",
        "\n",
        "# # Print the evaluation metrics on the test data\n",
        "# print(\"Test Accuracy:\", accuracy_test_dt)\n",
        "# print(\"Test F1 Score:\", f1_test_dt)\n",
        "# print(\"Test Precision:\", precision_test_dt)\n",
        "# print(\"Test Recall:\", recall_test_dt)\n",
        "\n",
        "# # Creating this because we want to save the result in form of csv and numpy\n",
        "# evaluation_metrics_dt_test = {\n",
        "#     \"Accuracy\": accuracy_test_dt,\n",
        "#     \"F1 Score\": f1_test_dt,\n",
        "#     \"Precision\": precision_test_dt,\n",
        "#     \"Recall\": recall_test_dt\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MXK5SQFa4Sda"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "\n",
        "# # Get the current working directory\n",
        "# current_directory = os.getcwd()\n",
        "\n",
        "# # Define the path to the results folder\n",
        "# results_folder = os.path.join(current_directory, \"results\")\n",
        "\n",
        "# # Define the dataset name\n",
        "# dataset_name = \"iris\"\n",
        "\n",
        "# # Create a folder for the current dataset within the results directory\n",
        "# dataset_results_folder = os.path.join(results_folder, dataset_name)\n",
        "# os.makedirs(dataset_results_folder, exist_ok=True)\n",
        "\n",
        "# # Create folder for decision tree results\n",
        "# dt_folder = os.path.join(dataset_results_folder, \"DT\")\n",
        "# os.makedirs(dt_folder, exist_ok=True)\n",
        "# # Save results_df to CSV\n",
        "# results_csv_path = os.path.join(dt_folder, \"all_splitseed_with_depth.csv\")\n",
        "# results_df.to_csv(results_csv_path, index=False)\n",
        "\n",
        "# # Save results_df to NumPy\n",
        "# results_npy_path = os.path.join(dt_folder, \"all_splitseed_with_depth.npy\")\n",
        "# np.save(results_npy_path, results)\n",
        "\n",
        "# # Path for DT csv file\n",
        "# dt_metrics_csv_path = os.path.join(dt_folder, \"evaluation_metrics_dt_test.csv\")\n",
        "# # saving this to DT folder\n",
        "# pd.DataFrame(evaluation_metrics_dt_test.items(), columns=[\"Metric\", \"Value\"]).to_csv(dt_metrics_csv_path, index=False)\n",
        "\n",
        "# # Path for DT numpy file\n",
        "# dt_metrics_npy_path = os.path.join(dt_folder, \"evaluation_metrics_dt_test.npy\")\n",
        "# # saving it to DT folder\n",
        "# np.save(dt_metrics_npy_path, evaluation_metrics_dt_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pdt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
