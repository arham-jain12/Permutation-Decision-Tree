{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8DXU9WKCp497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nyse_stock_data.data\n",
            "\n",
            "Maximum n_estimator and corresponding depth:\n",
            "n_estimator: 10.0\n",
            "Depth: 4\n",
            "\n",
            "Performance metrics on test set:\n",
            "Accuracy_test_rf: 0.9859154929577465\n",
            "F1 Score_test_rf: 0.9840985442329226\n",
            "Precision_test_rf: 0.9791666666666667\n",
            "Recall_test_rf: 0.9895833333333333\n",
            "timeseries.py\n",
            "Dataset not found.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Expected sequence or array-like, got <class 'NoneType'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     39\u001b[0m tscv \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39mnum_splits, test_size\u001b[38;5;241m=\u001b[39mtime_series_split_test_size)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# _______________________________________________________________________________\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Variable description:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets with the fixed seed\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Iterate over different numbers of estimators for Random Forest\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_estimators \u001b[38;5;129;01min\u001b[39;00m estimators_range:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Iterate over different depths for the decision tree\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pdt/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pdt/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2659\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m-> 2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2662\u001b[0m )\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/pdt/lib/python3.10/site-packages/sklearn/utils/validation.py:378\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    376\u001b[0m         x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'NoneType'>"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os\n",
        "import numpy as np\n",
        "from load import load\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "# Define the path to the datasets folder\n",
        "datasets_folder = os.path.join(current_directory, \"datasets\")\n",
        "# datasets = [dataset for dataset in os.listdir(datasets_folder) if not (dataset.startswith('.') or dataset in exclude_datasets)]\n",
        "datasets = [dataset for dataset in os.listdir(datasets_folder) if not (dataset.startswith('.'))]\n",
        "\n",
        "for dataset_name in datasets:\n",
        "    # importing dataset\n",
        "    print(dataset_name)\n",
        "    X, Y = load(dataset_name)\n",
        "        # Define the number of splits for time series split\n",
        "    num_splits = 5\n",
        "\n",
        "    # Fix the seed value for splitting data\n",
        "    split_seed = 42\n",
        "\n",
        "    # Define the range of depths for the decision tree\n",
        "    depth_range = range(2, 21)\n",
        "\n",
        "    # Initialize a list to store the results\n",
        "    results = []\n",
        "\n",
        "    # Define the range of estimators for the random forest\n",
        "    estimators_range = [10, 50, 100, 150, 1000]\n",
        "\n",
        "    # declaring test size for time series split\n",
        "    time_series_split_test_size = 15\n",
        "\n",
        "    # Perform time series split\n",
        "    tscv = TimeSeriesSplit(n_splits=num_splits, test_size=time_series_split_test_size)\n",
        "\n",
        "    # _______________________________________________________________________________\n",
        "\n",
        "    # Variable description:\n",
        "    # _______________________________________________________________________________\n",
        "\n",
        "    #     X               -   Data attributes.\n",
        "    #     y               -   Corresponding labels for X.\n",
        "    #     X_train         -   Data attributes for training (80% of the dataset).\n",
        "    #     y_train         -   Corresponding labels for X_train.\n",
        "    #     X_test          -   Data attributes for testing (20% of the dataset).\n",
        "    #     y_test          -   Corresponding labels for X_test.\n",
        "\n",
        "\n",
        "    # Split the data into training and testing sets with the fixed seed\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=split_seed)\n",
        "\n",
        "    # Iterate over different numbers of estimators for Random Forest\n",
        "    for n_estimators in estimators_range:\n",
        "        # Iterate over different depths for the decision tree\n",
        "        for depth in depth_range:\n",
        "            # Initialize lists to store evaluation metrics for each fold\n",
        "            accuracies = []\n",
        "            f1_scores = []\n",
        "            precisions = []\n",
        "            recalls = []\n",
        "\n",
        "            # Perform time series split\n",
        "            for train_index, test_index in tscv.split(X_train):\n",
        "                X_cv_train, X_cv_test = pd.DataFrame(X_train).iloc[train_index], pd.DataFrame(X_train).iloc[test_index]\n",
        "                y_cv_train, y_cv_test = pd.DataFrame(y_train).iloc[train_index], pd.DataFrame(y_train).iloc[test_index]\n",
        "\n",
        "                # Train the Random Forest model with the current number of estimators and depth\n",
        "                rf_classifier = RandomForestClassifier(criterion='gini', n_estimators=n_estimators, max_depth=depth, random_state= 21)\n",
        "                y_cv_train = np.ravel(y_cv_train)\n",
        "                rf_classifier.fit(X_cv_train, y_cv_train)\n",
        "\n",
        "                # Make predictions\n",
        "                y_pred = rf_classifier.predict(X_cv_test)\n",
        "\n",
        "                # Calculate evaluation metrics for this fold\n",
        "                accuracy = accuracy_score(y_cv_test, y_pred)\n",
        "                f1 = f1_score(y_cv_test, y_pred, average='macro')  # Use macro F1 score\n",
        "                precision = precision_score(y_cv_test, y_pred, average='macro', zero_division=1)\n",
        "                recall = recall_score(y_cv_test, y_pred, average='macro', zero_division=1)\n",
        "\n",
        "                # Append metrics to the lists\n",
        "                accuracies.append(accuracy)\n",
        "                f1_scores.append(f1)\n",
        "                precisions.append(precision)\n",
        "                recalls.append(recall)\n",
        "\n",
        "            # Calculate mean metrics across all folds\n",
        "            mean_accuracy = sum(accuracies) / len(accuracies)\n",
        "            mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "            mean_precision = sum(precisions) / len(precisions)\n",
        "            mean_recall = sum(recalls) / len(recalls)\n",
        "\n",
        "            # Store the results for this seed value and depth\n",
        "            results.append({\n",
        "                'Split Seed': split_seed,\n",
        "                'N_estimators': n_estimators,\n",
        "                'Depth of Tree': depth,\n",
        "                'Mean Accuracy': mean_accuracy,\n",
        "                'Mean F1 Score': mean_f1,\n",
        "                'Mean Precision': mean_precision,\n",
        "                'Mean Recall': mean_recall\n",
        "            })\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    # Group by 'N_estimators' and find the row with maximum 'Mean F1 Score' for each group\n",
        "    max_f1_per_estimator = results_df.loc[results_df.groupby('N_estimators')['Mean F1 Score'].idxmax()]\n",
        "\n",
        "    # Find the row with the maximum 'Mean F1 Score' across all 'N_estimators'\n",
        "    max_f1_row = max_f1_per_estimator.loc[max_f1_per_estimator['Mean F1 Score'].idxmax()]\n",
        "\n",
        "    # Extract the maximum n_estimator and corresponding depth with the minimum value\n",
        "    max_n_estimator = max_f1_row['N_estimators']\n",
        "    max_depth_for_estimator = max_f1_per_estimator.loc[max_f1_per_estimator['N_estimators'] == max_n_estimator, 'Depth of Tree'].min()\n",
        "\n",
        "    print(\"\\nMaximum n_estimator and corresponding depth:\")\n",
        "    print(\"n_estimator:\", max_n_estimator)\n",
        "    print(\"Depth:\", max_depth_for_estimator) \n",
        "\n",
        "        # Train Random Forest classifier with the best parameters\n",
        "    best_rf_classifier = RandomForestClassifier(criterion='gini',n_estimators=int(max_n_estimator), max_depth=max_depth_for_estimator, random_state= 21)\n",
        "    y_train = np.ravel(y_train)\n",
        "    best_rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_test_rf = best_rf_classifier.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy_test_rf = accuracy_score(y_test, y_pred_test_rf)\n",
        "    precision_test_rf = precision_score(y_test, y_pred_test_rf, average='macro', zero_division=1)\n",
        "    recall_test_rf = recall_score(y_test, y_pred_test_rf, average='macro', zero_division=1)\n",
        "    f1_test_rf = f1_score(y_test, y_pred_test_rf, average='macro')\n",
        "\n",
        "    print(\"\\nPerformance metrics on test set:\")\n",
        "    print(\"Accuracy_test_rf:\", accuracy_test_rf)\n",
        "    print(\"F1 Score_test_rf:\", f1_test_rf)\n",
        "    print(\"Precision_test_rf:\", precision_test_rf)\n",
        "    print(\"Recall_test_rf:\", recall_test_rf)\n",
        "\n",
        "    # Creating this because we want to save the result in form of csv and numpy\n",
        "    evaluation_metrics_rf_test = {\n",
        "        \"Accuracy\": accuracy_test_rf,\n",
        "        \"F1 Score\": f1_test_rf,\n",
        "        \"Precision\": precision_test_rf,\n",
        "        \"Recall\": recall_test_rf,\n",
        "        \"best_N_estimator_\":max_n_estimator,\n",
        "        \"Corresponding_depth\" : max_depth_for_estimator\n",
        "    }\n",
        "\n",
        "    # Define the path to the results folder\n",
        "    results_folder = os.path.join(current_directory, \"results\")\n",
        "\n",
        "    # Define the dataset name\n",
        "    dataset_name = dataset_name\n",
        "\n",
        "    # Create a folder for the current dataset within the results directory\n",
        "    dataset_results_folder = os.path.join(results_folder, dataset_name)\n",
        "    os.makedirs(dataset_results_folder, exist_ok=True)\n",
        "\n",
        "    # Create folder for random forest results\n",
        "    rf_folder = os.path.join(dataset_results_folder, \"RF_Gini\")\n",
        "    os.makedirs(rf_folder, exist_ok=True)\n",
        "\n",
        "    # Save results_df to CSV\n",
        "    results_csv_path = os.path.join(rf_folder, \"all_nestimator_with_depth.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "\n",
        "    # Save results_rf_gini to NumPy\n",
        "    results_npy_path = os.path.join(rf_folder, \"all_nestimator_with_depth.npy\")\n",
        "    np.save(results_npy_path, results)\n",
        "\n",
        "    # Path for RF csv file\n",
        "    rf_metrics_csv_path = os.path.join(rf_folder, \"evaluation_metrics_rf_test.csv\")\n",
        "    # saving this to DT folder\n",
        "    pd.DataFrame(evaluation_metrics_rf_test.items(), columns=[\"Metric\", \"Value\"]).to_csv(rf_metrics_csv_path, index=False)\n",
        "\n",
        "    # Path for RF numpy file\n",
        "    rf_metrics_npy_path = os.path.join(rf_folder, \"evaluation_metrics_rf_test.npy\")\n",
        "    # saving it to RF_Gini folder\n",
        "    np.save(rf_metrics_npy_path, evaluation_metrics_rf_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
